# AI Co-Host MVP – template only. Copy to .env.local and fill in values.
# Never commit .env.local or any file containing real secrets.
# Production: use a secret manager and inject env at runtime.

# --- ASR (Speech-to-Text) ---
ASR_PROVIDER=openai
OPENAI_API_KEY=
# Server-local Whisper (self-hosted) ASR:
# ASR_PROVIDER=whisper-local
# WHISPER_MODEL=base
# WHISPER_ENGINE=faster-whisper
# Optional: set Python interpreter for faster-whisper engine
# WHISPER_PYTHON_PATH=

# --- LLM ---
MODEL_PROVIDER=openai
OPENAI_MODEL_NAME=gpt-4o-mini
# Or Anthropic:
# MODEL_PROVIDER=anthropic
ANTHROPIC_MODEL_NAME=
ANTHROPIC_API_KEY=

# --- TTS (Text-to-Speech) ---
TTS_PROVIDER=google
# Google TTS: set API key (enable Text-to-Speech API in Cloud Console), or leave empty to use Application Default Credentials (set GOOGLE_APPLICATION_CREDENTIALS to service account JSON path) if you get 401 "API keys are not supported".
Google_Cloud_TTS_API_KEY=
# Default Google voice when a persona has no cadence profile or no voice override (e.g. default, hype, calm). Cadence personas (orator, podcast_host, bold_host, storyteller, pundit) set their own voice per personas/*.json voice.googleVoiceName.
# GOOGLE_TTS_VOICE_NAME=en-US-Neural2-D
# Or Azure:
# TTS_PROVIDER=azure
# AZURE_TTS_KEY=
# AZURE_TTS_REGION=
# AZURE_TTS_VOICE_NAME=

# --- Conversation backend mode ---
# Default is the discrete pipeline (VAD → ASR → LLM → TTS).
# Set to `personaplex` to use NVIDIA PersonaPlex as a speech-to-speech backend.
# See docs/PERSONAPLEX_SETUP.md.
CONVERSATION_BACKEND=asr-llm-tts
PERSONAPLEX_SERVER_URL=
# Voice prompt filename on the PersonaPlex server (commonly in its extracted voices/ directory).
# Examples: NATF2.pt, NATM1.pt, VARF0.pt
PERSONAPLEX_VOICE_PROMPT=
# Dev-only: allow self-signed SSL certs from PersonaPlex server.
# PERSONAPLEX_SSL_INSECURE=true
# Optional deterministic seed.
# PERSONAPLEX_SEED=42424242
# Turn timeout (ms) covering connect + stream + response.
# PERSONAPLEX_TURN_TIMEOUT_MS=30000
# Optional: fall back to ASR+LLM+TTS path if PersonaPlex fails.
# PERSONAPLEX_FALLBACK_TO_LLM=true
# Hugging Face token for PersonaPlex server (Python) to download gated model. Set HF_TOKEN when running the server (or in .env.local and source it).
# HF_TOKEN=

# --- Podium Outpost ---
NEXT_PUBLIC_PODIUM_API_URL=https://your-podium-api.com/api/v1
NEXT_PUBLIC_WEBSOCKET_ADDRESS=wss://your-ws.com/ws
NEXT_PUBLIC_OUTPOST_SERVER=meet.jit.si
# Podium JWT: set PODIUM_TOKEN or PODIUM_TOKEN_FILE (path to file containing token, e.g. /run/secrets/podium_token).
PODIUM_TOKEN=
# PODIUM_TOKEN_FILE=
PODIUM_OUTPOST_UUID=
# Use browser bot for real Jitsi audio (requires Playwright + bot-page).
USE_JITSI_BOT=false
# Optional: run Chromium with a visible window (requires DISPLAY). Does not fix receive-path diagnosis; use only if you need a visible browser for debugging.
# BROWSER_HEADED=true
# Optional: URL of minimal bot join page; if unset, Node serves bot-page/ on port 8766.
# BOT_PAGE_URL=http://localhost:8766/bot.html
# XMPP domain for Jitsi (Prosody VirtualHost). When meet is at a different public URL (e.g. outposts.myfihub.com), set this to the internal domain (e.g. meet.jitsi).
# JITSI_XMPP_DOMAIN=meet.jitsi
# XMPP MUC domain for conference rooms (room JID = roomName@muc). Jitsi Docker uses muc.<domain> (e.g. muc.meet.jitsi); if unset, bot defaults to conference.<JITSI_XMPP_DOMAIN>.
# JITSI_MUC_DOMAIN=muc.meet.jitsi
# First port to try for the Jitsi bot bridge (default 8766). If in use, subsequent ports are tried automatically; as a last resort it can bind to an ephemeral OS-assigned port.
# JITSI_BRIDGE_PORT=8766

# --- Audio debugging (optional) ---
# Add per-frame integrity header on Node→browser TTS frames and log browser acks.
# Useful to prove byte-level integrity across the WebSocket boundary.
# DEBUG_AUDIO_FRAMES=1
#
# Save short WAV captures under ./debug-audio (node TX + bot-page RX/OUT).
# SAVE_TTS_WAV=1

# --- Deterministic bot diagnostics (optional) ---
# BOT_DIAG=1 runs a 20s capture and prints a verdict + writes ./logs/diag/*_stats.jsonl (and WAVs if saveWav enabled).
# Use this to deterministically answer: NO_INBOUND_RTP vs WRONG_TRACK vs MIXER_WIRING vs PUBLISH_BYTES_NOT_INCREASING.
# BOT_DIAG=1
# BOT_DIAG_DURATION_MS=20000
#
# Receive contract threshold for pre-mixer maxAbs (0..32767). Tune so background noise doesn't pass.
# PRE_MIXER_PASS_THRESHOLD=200
# Grace period (ms) after track selection/rebind during which post_mixer 0 does not fail the receive contract (avoids false WRONG_TRACK from phased negotiation / decode delay). Default 6000.
# RECV_GRACE_AFTER_BIND_MS=6000
#
# Keep last N diag/audio artifacts (by mtime) in logs/diag and debug-audio.
# ARTIFACT_RETENTION_N=10
#
# Optional correlation id for multi-bot runs (otherwise a UUID is generated).
# SESSION_ID=

# --- Pipeline ---
# Silence (ms) after speech before end-of-turn. Lower = faster response, may cut off slow speakers. Recommend 300–500.
VAD_SILENCE_MS=500
# Optional: lower = more sensitive to quiet mics (energy-based VAD when webrtcvad unavailable). Default 500.
# VAD_ENERGY_THRESHOLD=300
# Optional: WebRTC VAD aggressiveness 0-3 (only if webrtcvad native module is used). Default 1.
# VAD_AGGRESSIVENESS=1
MAX_TURNS_IN_MEMORY=50
# Running summary: every N assistant turns, update a running summary and persist to ./data/sessions/<sessionId>.json.
# RUNNING_SUMMARY_TURN_INTERVAL=10
# RUNNING_SUMMARY_ENABLED=true

# MVP default: opener-first. Leave GREETING_TEXT empty to use LLM-generated opener after join.
# Pattern B (scripted cold open): set GREETING_TEXT to your line and OPENER_ENABLED=false.
GREETING_TEXT=
GREETING_DELAY_MS=2000

# Storyteller opener (LLM-generated) after join when GREETING_TEXT is empty. OPENER_DELAY_MS 500–1500 recommended.
OPENER_ENABLED=true
OPENER_DELAY_MS=1000
OPENER_MAX_TOKENS=180
TOPIC_SEED=

# --- Agent / Persona / Feedback ---
# Persona controls system prompt + feedback thresholds + (optionally) feedback context wording.
# Built-in personas: default, hype, calm
# default | hype | calm | influencer (influencer = more natural, podcast/influencer-style voice)
PERSONA_ID=default

# Optional: cadence profile for TTS/prosody (personas/ orator, podcast_host, bold_host, storyteller, pundit).
# When set, a cadence post-processor can use this profile's pause/rate/emphasis settings and SSML defaults.
# PERSONA_CADENCE_PROFILE=orator_v1

# Optional: filter which reactions are counted for feedback.
# - unset/empty: count ALL room reactions (room mood)
# - self: count only reactions targeting the bot's wallet address
# - 0x...: count only reactions targeting this wallet address
FEEDBACK_REACT_TO_ADDRESS=

# --- Multi-agent (Phase 1) ---
# Phase 1 = two or more AI agents in the same room; one Turn Coordinator process + one agent process per AI.
#
# === COORDINATOR PROCESS (run first: npm run start:coordinator) ===
# Port the coordinator HTTP server listens on. Agents will use COORDINATOR_URL pointing at this host:port.
# COORDINATOR_PORT=3001
#
# Collection window (ms) before turn decision. Lower = faster (e.g. 100–150 for single-agent); multi-agent may need 300.
# COORDINATOR_COLLECTION_MS=300
#
# Optional. Comma-separated id:DisplayName for round-robin order and name-addressing (e.g. "Alex, what do you think?").
# If unset, agent order is discovered from the first request batch.
# COORDINATOR_AGENTS=alex:Alex,jamie:Jamie
#
# === EACH AGENT PROCESS (npm start with the vars below) ===
# Set these only when running in multi-agent mode. When unset, the process runs as a single agent (no coordinator).
#
# Base URL of the Turn Coordinator (must match COORDINATOR_PORT / host where coordinator runs).
# COORDINATOR_URL=http://localhost:3001
#
# Unique id for this agent (e.g. alex, jamie). Required when COORDINATOR_URL is set.
# AGENT_ID=alex
#
# Display name for name-addressing; users can say "Alex, ..." to route the turn to this agent. Defaults to AGENT_ID.
# AGENT_DISPLAY_NAME=Alex
#
# Use a different PERSONA_ID per agent so each has a distinct voice and style (default, hype, calm, influencer).
# Same PODIUM_OUTPOST_UUID for all agents (same room); same or different PODIUM_TOKEN per agent (identity).

# --- Health server (agent process) ---
# Port for GET /health (liveness) and GET /ready (readiness). Default 8080.
# HEALTH_PORT=8080

# --- Reliability (self-healing) ---
# When true (default), watchdog triggers process exit(1) after sustained WS/conference/audio failures so orchestrator can restart.
# WATCHDOG_EXIT_ON_UNHEALTHY=true
# Max time (ms) allowed for room join (WS + Jitsi). If exceeded, process exits with 1.
# JOIN_MAX_MS=120000

# --- Logging --- debug, info, warn, error
LOG_LEVEL=info
# Optional: append all logs to a file (creates parent dirs). Use for troubleshooting when agents don't respond (see docs/PERSONAPLEX_SETUP.md).
# LOG_FILE=./logs/podium-voices.log
