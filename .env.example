# AI Co-Host MVP – copy to .env.local and fill in values. Do not commit .env.local.

# --- ASR (Speech-to-Text) ---
ASR_PROVIDER=openai
OPENAI_API_KEY=

# --- LLM ---
MODEL_PROVIDER=openai
OPENAI_MODEL_NAME=gpt-4o-mini
# Or Anthropic:
# MODEL_PROVIDER=anthropic
ANTHROPIC_MODEL_NAME=
ANTHROPIC_API_KEY=

# --- TTS (Text-to-Speech) ---
TTS_PROVIDER=google
# Google TTS: set API key (enable Text-to-Speech API in Cloud Console), or leave empty to use Application Default Credentials (set GOOGLE_APPLICATION_CREDENTIALS to service account JSON path) if you get 401 "API keys are not supported".
Google_Cloud_TTS_API_KEY=
# Or Azure:
# TTS_PROVIDER=azure
# AZURE_TTS_KEY=
# AZURE_TTS_REGION=
# AZURE_TTS_VOICE_NAME=

# --- Podium Outpost ---
NEXT_PUBLIC_PODIUM_API_URL=https://your-podium-api.com/api/v1
NEXT_PUBLIC_WEBSOCKET_ADDRESS=wss://your-ws.com/ws
NEXT_PUBLIC_OUTPOST_SERVER=meet.jit.si
PODIUM_TOKEN=
PODIUM_OUTPOST_UUID=
# Use browser bot for real Jitsi audio (requires Playwright + bot-page).
USE_JITSI_BOT=false
# Run Chromium headed (with a display). Use when headless yields silent remote audio; requires DISPLAY (e.g. Xvfb on servers). See docs/HEADED_BROWSER.md.
# BROWSER_HEADED=true
# Optional: URL of minimal bot join page; if unset, Node serves bot-page/ on port 8766.
# BOT_PAGE_URL=http://localhost:8766/bot.html
# XMPP domain for Jitsi (Prosody VirtualHost). When meet is at a different public URL (e.g. outposts.myfihub.com), set this to the internal domain (e.g. meet.jitsi).
# JITSI_XMPP_DOMAIN=meet.jitsi
# XMPP MUC domain for conference rooms (room JID = roomName@muc). Jitsi Docker uses muc.<domain> (e.g. muc.meet.jitsi); if unset, bot defaults to conference.<JITSI_XMPP_DOMAIN>.
# JITSI_MUC_DOMAIN=muc.meet.jitsi
# First port to try for the Jitsi bot bridge (default 8766). If in use, subsequent ports are tried automatically; as a last resort it can bind to an ephemeral OS-assigned port.
# JITSI_BRIDGE_PORT=8766

# --- Audio debugging (optional) ---
# Add per-frame integrity header on Node→browser TTS frames and log browser acks.
# Useful to prove byte-level integrity across the WebSocket boundary.
# DEBUG_AUDIO_FRAMES=1
#
# Save short WAV captures under ./debug-audio (node TX + bot-page RX/OUT).
# SAVE_TTS_WAV=1

# --- Pipeline ---
VAD_SILENCE_MS=500
# Optional: lower = more sensitive to quiet mics (energy-based VAD when webrtcvad unavailable). Default 500.
# VAD_ENERGY_THRESHOLD=300
# Optional: WebRTC VAD aggressiveness 0-3 (only if webrtcvad native module is used). Default 1.
# VAD_AGGRESSIVENESS=1
MAX_TURNS_IN_MEMORY=50

# Optional: speak a fixed greeting after join (empty = no greeting).
GREETING_TEXT= "Hello, I'm your AI co-host. I'm here to keep the conversation going and make sure everyone is having a good time."
GREETING_DELAY_MS=2000

# Optional: storyteller opener (LLM-generated) after join (used when GREETING_TEXT is empty).
# If OPENER_ENABLED is unset it defaults to true.
OPENER_ENABLED=true
OPENER_DELAY_MS=2500
OPENER_MAX_TOKENS=180
TOPIC_SEED=

# --- Logging --- debug, info, warn, error
LOG_LEVEL=info
# Optional: append all logs to a file (creates parent dirs). Useful when terminal scrollback is limited or for sharing debug output.
# LOG_FILE=./logs/podium-voices.log
