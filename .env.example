# AI Co-Host MVP – copy to .env.local and fill in values. Do not commit .env.local.

# --- ASR (Speech-to-Text) ---
ASR_PROVIDER=openai
OPENAI_API_KEY=
# Server-local Whisper (self-hosted) ASR:
# ASR_PROVIDER=whisper-local
# WHISPER_MODEL=base
# WHISPER_ENGINE=faster-whisper
# Optional: set Python interpreter for faster-whisper engine
# WHISPER_PYTHON_PATH=

# --- LLM ---
MODEL_PROVIDER=openai
OPENAI_MODEL_NAME=gpt-4o-mini
# Or Anthropic:
# MODEL_PROVIDER=anthropic
ANTHROPIC_MODEL_NAME=
ANTHROPIC_API_KEY=

# --- TTS (Text-to-Speech) ---
TTS_PROVIDER=google
# Google TTS: set API key (enable Text-to-Speech API in Cloud Console), or leave empty to use Application Default Credentials (set GOOGLE_APPLICATION_CREDENTIALS to service account JSON path) if you get 401 "API keys are not supported".
Google_Cloud_TTS_API_KEY=
# Or Azure:
# TTS_PROVIDER=azure
# AZURE_TTS_KEY=
# AZURE_TTS_REGION=
# AZURE_TTS_VOICE_NAME=

# --- Conversation backend mode ---
# Default is the discrete pipeline (VAD → ASR → LLM → TTS).
# Set to `personaplex` to use NVIDIA PersonaPlex as a speech-to-speech backend.
# See docs/PERSONAPLEX_SETUP.md.
CONVERSATION_BACKEND=asr-llm-tts
PERSONAPLEX_SERVER_URL=
# Voice prompt filename on the PersonaPlex server (commonly in its extracted voices/ directory).
# Examples: NATF2.pt, NATM1.pt, VARF0.pt
PERSONAPLEX_VOICE_PROMPT=
# Dev-only: allow self-signed SSL certs from PersonaPlex server.
# PERSONAPLEX_SSL_INSECURE=true
# Optional deterministic seed.
# PERSONAPLEX_SEED=42424242
# Turn timeout (ms) covering connect + stream + response.
# PERSONAPLEX_TURN_TIMEOUT_MS=30000
# Optional: fall back to ASR+LLM+TTS path if PersonaPlex fails.
# PERSONAPLEX_FALLBACK_TO_LLM=true
# Hugging Face token for PersonaPlex server (Python) to download gated model. Set HF_TOKEN when running the server (or in .env.local and source it).
# HF_TOKEN=

# --- Podium Outpost ---
NEXT_PUBLIC_PODIUM_API_URL=https://your-podium-api.com/api/v1
NEXT_PUBLIC_WEBSOCKET_ADDRESS=wss://your-ws.com/ws
NEXT_PUBLIC_OUTPOST_SERVER=meet.jit.si
PODIUM_TOKEN=
PODIUM_OUTPOST_UUID=
# Use browser bot for real Jitsi audio (requires Playwright + bot-page).
USE_JITSI_BOT=false
# Run Chromium headed (with a display). Use when headless yields silent remote audio; requires DISPLAY (e.g. Xvfb on servers). See docs/HEADED_BROWSER.md.
# BROWSER_HEADED=true
# Optional: URL of minimal bot join page; if unset, Node serves bot-page/ on port 8766.
# BOT_PAGE_URL=http://localhost:8766/bot.html
# XMPP domain for Jitsi (Prosody VirtualHost). When meet is at a different public URL (e.g. outposts.myfihub.com), set this to the internal domain (e.g. meet.jitsi).
# JITSI_XMPP_DOMAIN=meet.jitsi
# XMPP MUC domain for conference rooms (room JID = roomName@muc). Jitsi Docker uses muc.<domain> (e.g. muc.meet.jitsi); if unset, bot defaults to conference.<JITSI_XMPP_DOMAIN>.
# JITSI_MUC_DOMAIN=muc.meet.jitsi
# First port to try for the Jitsi bot bridge (default 8766). If in use, subsequent ports are tried automatically; as a last resort it can bind to an ephemeral OS-assigned port.
# JITSI_BRIDGE_PORT=8766

# --- Audio debugging (optional) ---
# Add per-frame integrity header on Node→browser TTS frames and log browser acks.
# Useful to prove byte-level integrity across the WebSocket boundary.
# DEBUG_AUDIO_FRAMES=1
#
# Save short WAV captures under ./debug-audio (node TX + bot-page RX/OUT).
# SAVE_TTS_WAV=1

# --- Deterministic bot diagnostics (optional) ---
# BOT_DIAG=1 runs a 20s capture and prints a verdict + writes ./logs/diag/*_stats.jsonl (and WAVs if saveWav enabled).
# Use this to deterministically answer: NO_INBOUND_RTP vs WRONG_TRACK vs MIXER_WIRING vs PUBLISH_BYTES_NOT_INCREASING.
# BOT_DIAG=1
# BOT_DIAG_DURATION_MS=20000
#
# Receive contract threshold for pre-mixer maxAbs (0..32767). Tune so background noise doesn't pass.
# PRE_MIXER_PASS_THRESHOLD=200
#
# Keep last N diag/audio artifacts (by mtime) in logs/diag and debug-audio.
# ARTIFACT_RETENTION_N=10
#
# Optional correlation id for multi-bot runs (otherwise a UUID is generated).
# SESSION_ID=

# --- Pipeline ---
VAD_SILENCE_MS=500
# Optional: lower = more sensitive to quiet mics (energy-based VAD when webrtcvad unavailable). Default 500.
# VAD_ENERGY_THRESHOLD=300
# Optional: WebRTC VAD aggressiveness 0-3 (only if webrtcvad native module is used). Default 1.
# VAD_AGGRESSIVENESS=1
MAX_TURNS_IN_MEMORY=50

# Optional: speak a fixed greeting after join (empty = no greeting).
GREETING_TEXT= "Hello, I'm your AI co-host. I'm here to keep the conversation going and make sure everyone is having a good time."
GREETING_DELAY_MS=2000

# Optional: storyteller opener (LLM-generated) after join (used when GREETING_TEXT is empty).
# If OPENER_ENABLED is unset it defaults to true.
OPENER_ENABLED=true
OPENER_DELAY_MS=2500
OPENER_MAX_TOKENS=180
TOPIC_SEED=

# --- Agent / Persona / Feedback ---
# Persona controls system prompt + feedback thresholds + (optionally) feedback context wording.
# Built-in personas: default, hype, calm
# default | hype | calm | influencer (influencer = more natural, podcast/influencer-style voice)
PERSONA_ID=default

# Optional: filter which reactions are counted for feedback.
# - unset/empty: count ALL room reactions (room mood)
# - self: count only reactions targeting the bot's wallet address
# - 0x...: count only reactions targeting this wallet address
FEEDBACK_REACT_TO_ADDRESS=

# --- Multi-agent (Phase 1) ---
# Phase 1 = two or more AI agents in the same room; one Turn Coordinator process + one agent process per AI.
#
# === COORDINATOR PROCESS (run first: npm run start:coordinator) ===
# Port the coordinator HTTP server listens on. Agents will use COORDINATOR_URL pointing at this host:port.
# COORDINATOR_PORT=3001
#
# Optional. Comma-separated id:DisplayName for round-robin order and name-addressing (e.g. "Alex, what do you think?").
# If unset, agent order is discovered from the first request batch.
# COORDINATOR_AGENTS=alex:Alex,jamie:Jamie
#
# === EACH AGENT PROCESS (npm start with the vars below) ===
# Set these only when running in multi-agent mode. When unset, the process runs as a single agent (no coordinator).
#
# Base URL of the Turn Coordinator (must match COORDINATOR_PORT / host where coordinator runs).
# COORDINATOR_URL=http://localhost:3001
#
# Unique id for this agent (e.g. alex, jamie). Required when COORDINATOR_URL is set.
# AGENT_ID=alex
#
# Display name for name-addressing; users can say "Alex, ..." to route the turn to this agent. Defaults to AGENT_ID.
# AGENT_DISPLAY_NAME=Alex
#
# Use a different PERSONA_ID per agent so each has a distinct voice and style (default, hype, calm, influencer).
# Same PODIUM_OUTPOST_UUID for all agents (same room); same or different PODIUM_TOKEN per agent (identity).

# --- Logging --- debug, info, warn, error
LOG_LEVEL=info
# Optional: append all logs to a file (creates parent dirs). Useful when terminal scrollback is limited or for sharing debug output.
# LOG_FILE=./logs/podium-voices.log
